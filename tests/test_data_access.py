#!/usr/bin/env python3
"""
æ•°æ®è®¿é—®å±‚æµ‹è¯•

æµ‹è¯•æ•°æ®è¯»å–å™¨çš„åŠŸèƒ½å’Œå…¼å®¹æ€§ã€‚
"""

import pytest
import asyncio
import tempfile
import json
import csv
import os
from typing import Dict, Any, List
from datetime import datetime

from app.dataReader.factory import DataReaderFactory
from app.dataReader.base import DataSourceType, QueryFilter, PlatformType
from app.dataReader.csv_reader import CsvDataReader
from app.dataReader.json_reader import JsonDataReader


async def test_config_validation():
    """æµ‹è¯•é…ç½®éªŒè¯"""
    print("ğŸ”§ æµ‹è¯•é…ç½®éªŒè¯...")
    
    print(f"ä¸»æ•°æ®æº: {settings.primary_data_source}")
    print(f"å¤‡ç”¨æ•°æ®æº: {settings.fallback_data_source}")
    print(f"è‡ªåŠ¨é™çº§: {settings.auto_fallback_enabled}")
    
    # æµ‹è¯•å„ç§æ•°æ®æºé…ç½®
    data_sources = ["supabase", "mysql", "csv", "json"]
    for source in data_sources:
        try:
            config = settings.get_data_source_config(source)
            print(f"âœ… {source} é…ç½®æœ‰æ•ˆ: {list(config.keys())}")
        except Exception as e:
            print(f"âŒ {source} é…ç½®é”™è¯¯: {e}")


async def test_csv_data_access():
    """æµ‹è¯•CSVæ•°æ®è®¿é—®"""
    print("\nğŸ“„ æµ‹è¯•CSVæ•°æ®è®¿é—®...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
    csv_path = Path(settings.csv_data_path)
    csv_path.mkdir(parents=True, exist_ok=True)
    
    csv_accessor = CsvDataAccessor(settings.get_data_source_config("csv"))
    
    try:
        # æµ‹è¯•åˆå§‹åŒ–
        await csv_accessor.initialize()
        print("âœ… CSVè®¿é—®å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await csv_accessor.health_check()
        print(f"CSVå¥åº·çŠ¶æ€: {health}")
        
        # æµ‹è¯•å¹³å°åˆ—è¡¨
        result = await csv_accessor.get_platform_list()
        print(f"å¹³å°åˆ—è¡¨æŸ¥è¯¢: success={result.success}, count={len(result.data or [])}")
        
        # æµ‹è¯•å†…å®¹æŸ¥è¯¢
        query = DataQuery(
            platform="xhs",
            limit=5
        )
        result = await csv_accessor.query_content(query)
        print(f"å†…å®¹æŸ¥è¯¢: success={result.success}, count={len(result.data or [])}")
        
    except Exception as e:
        print(f"âŒ CSVæµ‹è¯•å¤±è´¥: {e}")
    finally:
        await csv_accessor.close()


async def test_json_data_access():
    """æµ‹è¯•JSONæ•°æ®è®¿é—®"""
    print("\nğŸ“‹ æµ‹è¯•JSONæ•°æ®è®¿é—®...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
    json_path = Path(settings.json_data_path)
    json_path.mkdir(parents=True, exist_ok=True)
    
    json_accessor = JsonDataAccessor(settings.get_data_source_config("json"))
    
    try:
        # æµ‹è¯•åˆå§‹åŒ–
        await json_accessor.initialize()
        print("âœ… JSONè®¿é—®å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await json_accessor.health_check()
        print(f"JSONå¥åº·çŠ¶æ€: {health}")
        
        # æµ‹è¯•å¹³å°åˆ—è¡¨
        result = await json_accessor.get_platform_list()
        print(f"å¹³å°åˆ—è¡¨æŸ¥è¯¢: success={result.success}, count={len(result.data or [])}")
        
        # æµ‹è¯•æœç´¢åŠŸèƒ½
        result = await json_accessor.search_content("æµ‹è¯•", platform="douyin")
        print(f"æœç´¢æµ‹è¯•: success={result.success}, count={len(result.data or [])}")
        
    except Exception as e:
        print(f"âŒ JSONæµ‹è¯•å¤±è´¥: {e}")
    finally:
        await json_accessor.close()


async def test_data_access_manager():
    """æµ‹è¯•æ•°æ®è®¿é—®ç®¡ç†å™¨"""
    print("\nğŸ¯ æµ‹è¯•æ•°æ®è®¿é—®ç®¡ç†å™¨...")
    
    try:
        # åˆå§‹åŒ–ç®¡ç†å™¨
        await data_access_manager.initialize()
        print("âœ… æ•°æ®è®¿é—®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ä¸»æ•°æ®æº
        primary = await data_access_manager.get_primary_access()
        if primary:
            print(f"âœ… ä¸»æ•°æ®æºå¯ç”¨: {type(primary).__name__}")
            
            # æµ‹è¯•ä¸»æ•°æ®æºæŸ¥è¯¢
            result = await primary.get_platform_list()
            print(f"ä¸»æ•°æ®æºæŸ¥è¯¢: success={result.success}")
        else:
            print("âŒ ä¸»æ•°æ®æºä¸å¯ç”¨")
        
        # æµ‹è¯•é™çº§æœºåˆ¶
        fallback = await data_access_manager.get_access_with_fallback()
        if fallback:
            print(f"âœ… é™çº§æ•°æ®æºå¯ç”¨: {type(fallback).__name__}")
            
            # æµ‹è¯•é™çº§æ•°æ®æºæŸ¥è¯¢
            result = await fallback.get_platform_list()
            print(f"é™çº§æ•°æ®æºæŸ¥è¯¢: success={result.success}")
        else:
            print("âŒ é™çº§æ•°æ®æºä¸å¯ç”¨")
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = await data_access_manager.health_check()
        print(f"ç®¡ç†å™¨å¥åº·çŠ¶æ€: {health}")
        
        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = await data_access_manager.get_statistics()
        print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")
        
    except Exception as e:
        print(f"âŒ ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")


async def test_query_functionality():
    """æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½...")
    
    try:
        accessor = await data_access_manager.get_access_with_fallback()
        if not accessor:
            print("âŒ æ— å¯ç”¨æ•°æ®è®¿é—®å™¨")
            return
        
        # æµ‹è¯•åŸºç¡€æŸ¥è¯¢
        query1 = DataQuery(platform="xhs", limit=10)
        result1 = await accessor.query_content(query1)
        print(f"åŸºç¡€æŸ¥è¯¢: success={result1.success}, count={len(result1.data or [])}")
        
        # æµ‹è¯•å¸¦è¿‡æ»¤å™¨çš„æŸ¥è¯¢
        filter_obj = QueryFilter(
            user_id="test_user",
            start_date="2024-01-01",
            end_date="2024-12-31"
        )
        query2 = DataQuery(platform="douyin", limit=5, filters=filter_obj)
        result2 = await accessor.query_content(query2)
        print(f"è¿‡æ»¤æŸ¥è¯¢: success={result2.success}, count={len(result2.data or [])}")
        
        # æµ‹è¯•è¯„è®ºæŸ¥è¯¢
        result3 = await accessor.query_comments("test_content_id", platform="xhs")
        print(f"è¯„è®ºæŸ¥è¯¢: success={result3.success}, count={len(result3.data or [])}")
        
        # æµ‹è¯•ç”¨æˆ·å†…å®¹æŸ¥è¯¢
        result4 = await accessor.get_user_content("test_user_id", platform="bilibili")
        print(f"ç”¨æˆ·å†…å®¹æŸ¥è¯¢: success={result4.success}, count={len(result4.data or [])}")
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")


async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸš¨ æµ‹è¯•é”™è¯¯å¤„ç†...")
    
    try:
        # æµ‹è¯•æ— æ•ˆå¹³å°
        invalid_query = DataQuery(platform="invalid_platform", limit=10)
        accessor = await data_access_manager.get_access_with_fallback()
        
        if accessor:
            result = await accessor.query_content(invalid_query)
            print(f"æ— æ•ˆå¹³å°æŸ¥è¯¢: success={result.success}, message='{result.message}'")
        
        # æµ‹è¯•æ— æ•ˆé…ç½®
        try:
            settings.get_data_source_config("invalid_source")
        except ValueError as e:
            print(f"âœ… æ— æ•ˆé…ç½®æ­£ç¡®æŠ›å‡ºå¼‚å¸¸: {e}")
        
        print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")


async def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•"""
    print("\nğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    
    import json
    import csv
    from datetime import datetime
    
    # ç¤ºä¾‹æ•°æ®
    sample_xhs_data = [
        {
            "note_id": "test_note_001",
            "title": "æµ‹è¯•å°çº¢ä¹¦ç¬”è®°1",
            "desc": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç¬”è®°",
            "user_id": "test_user_001",
            "nickname": "æµ‹è¯•ç”¨æˆ·1",
            "liked_count": "100",
            "collected_count": "50",
            "time": int(datetime.now().timestamp() * 1000)
        },
        {
            "note_id": "test_note_002", 
            "title": "æµ‹è¯•å°çº¢ä¹¦ç¬”è®°2",
            "desc": "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•ç¬”è®°",
            "user_id": "test_user_002",
            "nickname": "æµ‹è¯•ç”¨æˆ·2",
            "liked_count": "200",
            "collected_count": "80",
            "time": int(datetime.now().timestamp() * 1000)
        }
    ]
    
    # åˆ›å»ºCSVç¤ºä¾‹æ•°æ®
    csv_path = Path(settings.csv_data_path)
    csv_path.mkdir(parents=True, exist_ok=True)
    
    csv_file = csv_path / "xhs_note.csv"
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if sample_xhs_data:
            writer = csv.DictWriter(f, fieldnames=sample_xhs_data[0].keys())
            writer.writeheader()
            writer.writerows(sample_xhs_data)
    
    print(f"âœ… åˆ›å»ºCSVç¤ºä¾‹æ•°æ®: {csv_file}")
    
    # åˆ›å»ºJSONç¤ºä¾‹æ•°æ®
    json_path = Path(settings.json_data_path)
    json_path.mkdir(parents=True, exist_ok=True)
    
    json_file = json_path / "xhs_note.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(sample_xhs_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… åˆ›å»ºJSONç¤ºä¾‹æ•°æ®: {json_file}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ•°æ®è®¿é—®å±‚ä¸“é¡¹æµ‹è¯•å¼€å§‹")
    print("="*50)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    await create_sample_data()
    
    # é…ç½®éªŒè¯
    await test_config_validation()
    
    # CSVæ•°æ®è®¿é—®æµ‹è¯•
    await test_csv_data_access()
    
    # JSONæ•°æ®è®¿é—®æµ‹è¯•
    await test_json_data_access()
    
    # æ•°æ®è®¿é—®ç®¡ç†å™¨æµ‹è¯•
    await test_data_access_manager()
    
    # æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•
    await test_query_functionality()
    
    # é”™è¯¯å¤„ç†æµ‹è¯•
    await test_error_handling()
    
    print("\nâœ… æ•°æ®è®¿é—®å±‚æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(main()) 